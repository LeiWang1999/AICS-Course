### 7.1 列举出目前市场上至少三种品牌和型号的人工智能加速装置的峰值算力、带宽和功耗。

### 7.2 本章所介绍的单核深度学习处理器的片内存储和传统CPU的片上缓存有什么区别？

### 7.3 本章所介绍的单核深度学习处理器的访存行为与传统的CPU有什么区别？

### 7.4 本章所介绍的但和深度学习处理器的指令译码过程与传统的CPU体系结构有什么区别？

### 7.5 怎样改进才能使本章所介绍的单核深度学习处理器能够支持乱序执行的功能？从应用的角度考虑，深度学习处理器是否有必要支持乱系执行功能？

### 7.6 请简述DMA的工作过程及其关键要点。

### 7.7 假设有一个单核的神经网络处理器，包含用于存放权重的片上存储WRAM共256KB，用于存放输入/输出神经元数据的片上存储NRAM共128KB，一个矩阵运算单元每个时钟周期内可完成256个32位浮点乘累加运算，该芯片运行频率位1Ghz，片外访存总带宽为64GB/s。假设运算器利用率为100%且不考虑延迟，访存带宽利用率为100%且不考虑延迟。

可以使用以下几种简化指令：

- move ram_type1 ram_type2 size，用于从 ram_type1向 ram_type2 传输size个字节的数据。其中，ram_type可选DRAM、NRAM和WRAM、
- compute compute_type num，用执行运算总量为num的compute_type类型的运算，其中，compute_type可选MAC_32、MAC_16、ADD_32、ADD_16、SUB_32、SUB_16、MUL_32、MUL_16、DIV_32、DIV_16等。
- loop loop_time ... endloop，用于表示执行循环体loop_time次。
- sync，同步指令，表示在此之前的指令必须都执行完成才能继续执行后续的指令。

请使用上述指令完成以下任务，并估计执行时间：一个全连接层，其输入的神经元个数为1X256、权重矩阵的大小为256X1，所有数据均为32位宽的浮点数。

### 7.8 利用习题7.7所述的处理器和指令完成以下任务，并估算运行时间：一个全连接层，其输入神经元的个数为32x256，权重矩阵的大小为256x128，所有数据均为32位宽的浮点数。

### 7.9 利用习题7.7所述的处理器和指令完成以下任务，并估算运行时间：一个全连接层，其输入神经元的个数为1024x256，权重矩阵的大小为256x128，所有数据均为32位宽的浮点数。

### 7.10 对于习题7.9的情况，假设权重和输入数据具有一定的稀疏性，权重可以经过稀疏编码被压缩为原来体积的1/4，输入神经元数据可以被压缩为原来体积的1/2。重新估算习题7.9的执行时间。

### 7.11 假设有一个四核神经网络处理器，每个核都与习题7.7中的单核神经网络处理器相同（除了片外访带宽 ）。除此之外，这四个完全相同的核组成的Cluster还包含一个由四核共享的片上存储SharedRAM，大小为2MB。这个芯片的片外访存总带宽为128GB/s，SharedRAM与每一个单核处理器之间的带宽均为1TB/s。该芯片所支持的指令与习题7.7相同，并在其基础上增加SharedRAM作为一种新的ram_type。请用所述指令完成以下任务，并估算运行时间：一个全连接层，其输入神经元为32x256，权重矩阵的大小为256x128，所有数据均为32位宽的浮点数。

### 7.12 利用习题7.11所述的多核处理器和指令完成一下任务，并估算运行时间：一个全连接层，其输入神经元的个数为1024x256，权重矩阵的大小为256x2048，所有数据均为32位宽的浮点数。