### 5.1 请调研学习Eager API的使用。使用Eager API实现两个数的加法和矩阵乘法。

[TensorFlor Eager](https://www.tensorflow.org/guide/eager?hl=zh-cn)

Code:https://github.com/LeiWang1999/AICS-Course/tree/master/Code/5.1.Eager.tensorflow

### 5.2 现有常见的编程框架的执行模式分为静态图模式和动态图模式，说明这两种执行模式各有什么优缺点。

静态图和动态图的区别在于，静态图需要我们事先定义好一张计算图并进行编译，之后在运行的过程中我们是对同一张计算图重复运算，不能更改计算图的内容。而动态图则在使用时创建。

静态图只需要编译一次，重复使用，这在部署上很实用，比如可以在磁盘中序列化，保存整个网络的结构，可以重载，而动态图则需要重复之前的代码。但编写静态图的程序需要使用特定的语法，增加了学习的成本，动态图可以直接使用Python语法，并且在调试过程中方便Debug。

### 5.3 使用GPU计算时，试分析在单机单卡、单机多卡、多机多卡的设备下训练卷积神经网络流程上的区别。其中哪些步骤是可以并行的，哪些步骤是必须串行的？

**单GPU训练** 一般代码比较简单，并且能满足我们的基本需求，通常做法是设定变量CUDA_VISIBLE_DEVICES的值为某一块GPU来Mask我们机器上的GPU设备，虽然有时当我们忘了设定该变量时程序会自动占用所有的GPU资源，但如果没有相应的代码去分配掌控GPU资源的使用的话，程序还是只会利用到第一张卡的计算资源，其他的资源则仅是占用浪费状态。

**多GPU训练** 则可以从两个方面提升我们模型训练的上限：1. 超过单卡显存上限的模型大小， 2. 更大的Batch Size和更快训练速度。相应的，目前各大主流框架的多GPU训练一般存在两种模式：

- **模型并行** ：分布式系统中的不同GPU负责网络模型的不同部分，进而可以 **构建超过单卡显存容量大小的模型** 。比如，可以将神经网络的不同层分配到不同的GPU设备，或者将不同的参数变量分配到不同的GPU设备。
- **数据并行** ：不同的 GPU设备有同一模型的多个副本，将数据分片并分配到每个GPU上，然后将所有GPU的计算结果按照某种方式合并，进而可以**增加训练数据的Batch Size**。

多机多卡相比较于单机多卡，其使得模型训练的上限进一步突破。一般我们一台服务器只支持8张GPU卡，而采用分布式的多机多卡训练方式，可以将几十甚至几百台服务器调度起来一起训练一个模型。

但相比于单机多卡，多机多卡分布式训练方式的配置更复杂一些，不仅要保证多台机器之间是可以互相通信的，还需要配置不同机器之间的角色以及不同机器之间梯度传递。

### 5.4 查看TensorFlow源码，在python/keras中，查找关于ImageNet数据集数据预处理相关的代码，学习几种常用的数据预处理方法，并列举出keras里实现的数据预处理方法。

### 5.5 查看TensorFlow源码，在python/ops中，查找涉及注册sin算子梯度计算和maxpool算子梯度计算的代码，查看相关文件里注册其他算子的代码，学习了解注册Python层算子。

### 5.6 查看TensorFlow源码，在core/ops中，查找涉及conv算子的代码，请简述算子注册的流程。

### 5.7 查看TensorFlow源码，在core/kernel中，查找涉及conv算子的代码，请简述卷积的具体实现。

### 5.8 TensorFlow使用SWIG（Simplified Wrapper and Interface Generator），使得Python语言能调用底层C/C++的接口。学习了解SWIG的基本原理，并在源码中找到和SWIG有关的部分。请列出SWIG的一个使用实例。

### 5.9 现在常用的几种机器学习框架均支持混合精度（Mixed Precision）训练方法，该方法采用半精度浮点做正向传播计算，使用单精度浮点做反向传播计算，在训练时需要同时存储半精度和单精度两份数据。调研了解Mixed Precision的具体实现方法，并借鉴此思想，简述如何实现稀疏卷积神经网络模型的训练。注：稀疏卷积神经网络采用稠密矩阵或者稀疏矩阵方法存储均可。

### 5.10 使用TF_CPP_MIN_VLOG_LEVEL环境变量，设置级别为3。试运行课本中数据流图剪枝相关程序，查看并分析输出日志。

### 5.11 试分析算子融合比非融合提高计算效率的原因。在常见的分类网络中，算子融合对具有哪些特征的网络带来的加速比更大？

### 5.12 在MNIST数据集上，不使用常见的机器学习框架，可以借助Numpy等计算哭，实现一个三层的全连接网络的预测与训练。进一步地，使用习题5.9中的方法，实现一个稀疏全连接网络的训练，建议每一层的稀疏度为50%，且稀疏度可以随着训练过程从0%逐渐到达50%。注：卷积层和全连接层的稀疏度指权重中0元素的占比。