#include "mlu.h"
#define ROUND 256
__mlu_entry__ void gemm16Kernel(half *outputDDR, int8_t *input1DDR, int8_t *input2DDR,
	uint32_t m, uint32_t k, uint32_t n, int16_t pos) {
	__nram__ int8_t input1NRAM[256*256];
	__nram__ int8_t input2NRAM[256*256];
	__nram__ int8_t input2NRAM_tmp[256*256];
	__wram__ int8_t input2WRAM[256*256];
	__nram__ half outputNRAM[256*256];
	__memcpy(input1NRAM, input1DDR, m * k * sizeof(int8_t), GDRAM2NRAM); 
							//在这里将左矩阵一次性拷入NRAM
	
    int all_round = n / ( taskDim * ROUND);   //因为现在使用16个核同时运算，所以每个核循环的次数也相应减少
    int32_t dst_stride = (ROUND * k / 64) * sizeof(int8_t);
    int32_t src_stride = k * sizeof(int8_t);
    int32_t size = k * sizeof(int8_t);
    int32_t total_times = ROUND / 64;
    __mlu_shared__ int8_t input2SRAM[256*1024];

    //_bang_printf("taskDim=%d,clusterId=%d,coreId=%d\n",taskDim,clusterId,coreId);
    for(int i = 0; i < all_round; i++)
    {
        __memcpy(input2SRAM, input2DDR + ROUND * (i * taskDim + clusterId * 4) * k , k * ROUND * 4 * sizeof(int8_t), GDRAM2SRAM);

        __sync_cluster();   //设置sync barrier

        // copy SRAM2NRAM
        __memcpy(input2NRAM_tmp, input2SRAM + ROUND * coreId * k , k * ROUND * sizeof(int8_t), SRAM2NRAM);

        for (int j = 0; j < total_times; j++) {
            __memcpy(input2NRAM + j * k, input2NRAM_tmp + j * 64 * k,
                                     size, NRAM2NRAM, dst_stride, src_stride, 64);
        }

        // copy NRAM2WRAM
        __memcpy(input2WRAM, input2NRAM, ROUND*k*sizeof(int8_t), NRAM2WRAM);

        // compute
        __bang_conv(outputNRAM, input1NRAM, input2WRAM, k, m, 1, 1, 1, 1, 1, ROUND, pos);

        // copy NRAM2GDRAM
        for (int j = 0; j < m; j++) {  
              __memcpy(outputDDR + (i * taskDim + taskId) * ROUND + j * n,   
                        outputNRAM + j * ROUND, ROUND * sizeof(half), NRAM2GDRAM);
        }
        __sync_cluster();   //设置sync barrier
    }
}
